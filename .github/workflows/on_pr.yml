name: CI - dbt PR Validation

on:
  workflow_dispatch: # Manual run option
  pull_request:
    branches: ["master"]
    paths:
      - "models/**"
      - "seeds/**"

jobs:
  ci-dbt:
    runs-on: ubuntu-latest
    env:
      REGISTRY: ghcr.io
      IMAGE_NAME: ${{ github.repository }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history needed for git diff

      - name: Detect changed models and seeds
        id: changes
        run: |
          git fetch origin master || true

          ADDED_MODIFIED=$(git diff --name-only --diff-filter=AM origin/master -- "models/" "seeds/" | grep -E '\.sql$|\.csv$' || true)
          DELETED=$(git diff --name-only --diff-filter=D origin/master -- "models/" "seeds/" | grep -E '\.sql$|\.csv$' || true)

          echo "Added/Modified files:"
          echo "$ADDED_MODIFIED"
          echo "Deleted files:"
          echo "$DELETED"

          # Use multiline GitHub output syntax
          {
            echo "added_or_modified<<EOF"
            echo "$ADDED_MODIFIED"
            echo "EOF"
            echo "deleted<<EOF"
            echo "$DELETED"
            echo "EOF"
          } >> $GITHUB_OUTPUT

      - name: Build dbt image (no push)
        uses: docker/build-push-action@v4
        with:
          context: .
          push: false
          tags: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:ci
          load: true
          secrets: |
            aws_region=${{ secrets.AWS_REGION }}
            s3_key=${{ secrets.S3_ACCESS_KEY_ID }}
            s3_secret=${{ secrets.S3_SECRET_ACCESS_KEY }}
            pg_host=${{ secrets.POSTGRES_HOST }}
            pg_port=${{ secrets.POSTGRES_PORT }}
            pg_user=${{ secrets.POSTGRES_USER }}
            pg_password=${{ secrets.POSTGRES_PASSWORD }}
            pg_database=${{ secrets.POSTGRES_DATABASE }}

      - name: Run dbt for added/modified models/seeds
        if: ${{ steps.changes.outputs.added_or_modified != '' }}
        run: |
          # Read changed files into an array safely
          MODELS=()
          while IFS= read -r line; do
            [ -n "$line" ] && MODELS+=("$line")
          done <<< "${{ steps.changes.outputs.added_or_modified }}"

          # Build list for full-refresh
          FULL_REFRESH_ARGS=()
          for m in "${MODELS[@]}"; do
            FULL_REFRESH_ARGS+=("path:$m+")
          done

          echo ">>> Running dbt full-refresh build for models: ${MODELS[*]}"
          echo "docker run ... build -s ${FULL_REFRESH_ARGS[*]} --vars '{ci_row_limit: 1000}' --full-refresh"
          docker run --rm \
            -e AWS_REGION=${{ secrets.AWS_REGION }} \
            -e S3_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }} \
            -e S3_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }} \
            -e POSTGRES_HOST=${{ secrets.POSTGRES_HOST }} \
            -e POSTGRES_PORT=${{ secrets.POSTGRES_PORT }} \
            -e POSTGRES_USER=${{ secrets.POSTGRES_USER }} \
            -e POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD }} \
            -e POSTGRES_DATABASE=${{ secrets.POSTGRES_DATABASE }} \
            ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:ci \
            build -s "${FULL_REFRESH_ARGS[@]}" --vars '{ci_row_limit: 1000}' --full-refresh

          # Build list for incremental run
          INCREMENTAL_ARGS=()
          for m in "${MODELS[@]}"; do
            INCREMENTAL_ARGS+=("path:$m+,config.materialized:incremental")
          done

          echo ">>> Running dbt incremental check for models: ${MODELS[*]}"
          echo "docker run ... build -s ${INCREMENTAL_ARGS[*]} --vars '{ci_row_limit: 1000}'"
          docker run --rm \
            -e AWS_REGION=${{ secrets.AWS_REGION }} \
            -e S3_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }} \
            -e S3_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }} \
            -e POSTGRES_HOST=${{ secrets.POSTGRES_HOST }} \
            -e POSTGRES_PORT=${{ secrets.POSTGRES_PORT }} \
            -e POSTGRES_USER=${{ secrets.POSTGRES_USER }} \
            -e POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD }} \
            -e POSTGRES_DATABASE=${{ secrets.POSTGRES_DATABASE }} \
            ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:ci \
            build -s "${INCREMENTAL_ARGS[@]}" --vars '{ci_row_limit: 1000}'

      - name: Run dbt for deleted models/seeds
        if: ${{ steps.changes.outputs.deleted != '' }}
        run: |
          echo ">>> Handling deleted models/seeds"
          echo "${{ steps.changes.outputs.deleted }}" | while read path; do
            [ -z "$path" ] && continue
            echo ">>> Deleted: $path"
          done

          docker run --rm \
            -e AWS_REGION=${{ secrets.AWS_REGION }} \
            -e S3_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }} \
            -e S3_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }} \
            -e POSTGRES_HOST=${{ secrets.POSTGRES_HOST }} \
            -e POSTGRES_PORT=${{ secrets.POSTGRES_PORT }} \
            -e POSTGRES_USER=${{ secrets.POSTGRES_USER }} \
            -e POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD }} \
            -e POSTGRES_DATABASE=${{ secrets.POSTGRES_DATABASE }} \
            ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:ci \
            build --empty --full-refresh --vars '{ci_row_limit: 1000}'
